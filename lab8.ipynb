{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d495b6e",
   "metadata": {},
   "source": [
    "## <center>Лабораторная работа № 8 'Генерация текста на основе “Алисы в стране чудес”'<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd92e35",
   "metadata": {},
   "source": [
    "### <center>Выполнила студентка 3 курса группы БФИ2001 Калмыкова Дарья<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d12577",
   "metadata": {},
   "source": [
    "### Цель\n",
    "Использовать рекуррентные нейронные сети в качестве генеративных моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc29bdd9",
   "metadata": {},
   "source": [
    "### Задачи\n",
    "* Ознакомиться с генерацией текста\n",
    "* Ознакомиться с системой Callback в Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdacbfe",
   "metadata": {},
   "source": [
    "### Требования\n",
    "1. Реализовать модель ИНС, которая будет генерировать текст\n",
    "2. Написать собственный CallBack, который будет показывать то как генерируется \n",
    "текст во время обучения (то есть раз в какое-то количество эпох генирировать и \n",
    "выводить текст у необученной модели)\n",
    "3. Отследить процесс обучения при помощи TensorFlowCallBack (TensorBoard), в \n",
    "отчете привести результаты и их анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1925dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import codecs\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935e949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObj = codecs.open( \"./wonderland.txt\", \"r\", \"utf_8\" )\n",
    "raw_text = fileObj.read()\n",
    "text_clear = re.sub(r\"[\\r\\n]\", '', raw_text)\n",
    "raw_text = text_clear.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f2ff989",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63c44789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c5a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a2cb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  141208\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "print(\"Total Characters: \", n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e917340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocab:  48\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7de4d99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  141108\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7e33235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6edac89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d253efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', \n",
    "                             verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf8dec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.9994\n",
      "Epoch 1: loss improved from inf to 2.99945, saving model to weights-improvement-01-2.9994.hdf5\n",
      "1103/1103 [==============================] - 340s 306ms/step - loss: 2.9994\n",
      "Epoch 2/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.8329\n",
      "Epoch 2: loss improved from 2.99945 to 2.83286, saving model to weights-improvement-02-2.8329.hdf5\n",
      "1103/1103 [==============================] - 337s 306ms/step - loss: 2.8329\n",
      "Epoch 3/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.7443\n",
      "Epoch 3: loss improved from 2.83286 to 2.74433, saving model to weights-improvement-03-2.7443.hdf5\n",
      "1103/1103 [==============================] - 359s 325ms/step - loss: 2.7443\n",
      "Epoch 4/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.6822\n",
      "Epoch 4: loss improved from 2.74433 to 2.68223, saving model to weights-improvement-04-2.6822.hdf5\n",
      "1103/1103 [==============================] - 366s 332ms/step - loss: 2.6822\n",
      "Epoch 5/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.6241\n",
      "Epoch 5: loss improved from 2.68223 to 2.62412, saving model to weights-improvement-05-2.6241.hdf5\n",
      "1103/1103 [==============================] - 366s 332ms/step - loss: 2.6241\n",
      "Epoch 6/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.5671\n",
      "Epoch 6: loss improved from 2.62412 to 2.56710, saving model to weights-improvement-06-2.5671.hdf5\n",
      "1103/1103 [==============================] - 380s 345ms/step - loss: 2.5671\n",
      "Epoch 7/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.5177\n",
      "Epoch 7: loss improved from 2.56710 to 2.51767, saving model to weights-improvement-07-2.5177.hdf5\n",
      "1103/1103 [==============================] - 357s 324ms/step - loss: 2.5177\n",
      "Epoch 8/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.4724\n",
      "Epoch 8: loss improved from 2.51767 to 2.47237, saving model to weights-improvement-08-2.4724.hdf5\n",
      "1103/1103 [==============================] - 362s 328ms/step - loss: 2.4724\n",
      "Epoch 9/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.4291\n",
      "Epoch 9: loss improved from 2.47237 to 2.42905, saving model to weights-improvement-09-2.4291.hdf5\n",
      "1103/1103 [==============================] - 344s 312ms/step - loss: 2.4291\n",
      "Epoch 10/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.3909\n",
      "Epoch 10: loss improved from 2.42905 to 2.39094, saving model to weights-improvement-10-2.3909.hdf5\n",
      "1103/1103 [==============================] - 341s 309ms/step - loss: 2.3909\n",
      "Epoch 11/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.3515\n",
      "Epoch 11: loss improved from 2.39094 to 2.35151, saving model to weights-improvement-11-2.3515.hdf5\n",
      "1103/1103 [==============================] - 338s 306ms/step - loss: 2.3515\n",
      "Epoch 12/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.3130\n",
      "Epoch 12: loss improved from 2.35151 to 2.31301, saving model to weights-improvement-12-2.3130.hdf5\n",
      "1103/1103 [==============================] - 336s 305ms/step - loss: 2.3130\n",
      "Epoch 13/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.2795\n",
      "Epoch 13: loss improved from 2.31301 to 2.27952, saving model to weights-improvement-13-2.2795.hdf5\n",
      "1103/1103 [==============================] - 340s 308ms/step - loss: 2.2795\n",
      "Epoch 14/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.2446\n",
      "Epoch 14: loss improved from 2.27952 to 2.24457, saving model to weights-improvement-14-2.2446.hdf5\n",
      "1103/1103 [==============================] - 351s 318ms/step - loss: 2.2446\n",
      "Epoch 15/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.2113\n",
      "Epoch 15: loss improved from 2.24457 to 2.21126, saving model to weights-improvement-15-2.2113.hdf5\n",
      "1103/1103 [==============================] - 359s 326ms/step - loss: 2.2113\n",
      "Epoch 16/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.1785\n",
      "Epoch 16: loss improved from 2.21126 to 2.17850, saving model to weights-improvement-16-2.1785.hdf5\n",
      "1103/1103 [==============================] - 346s 313ms/step - loss: 2.1785\n",
      "Epoch 17/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.1483\n",
      "Epoch 17: loss improved from 2.17850 to 2.14832, saving model to weights-improvement-17-2.1483.hdf5\n",
      "1103/1103 [==============================] - 343s 311ms/step - loss: 2.1483\n",
      "Epoch 18/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.1175\n",
      "Epoch 18: loss improved from 2.14832 to 2.11755, saving model to weights-improvement-18-2.1175.hdf5\n",
      "1103/1103 [==============================] - 340s 309ms/step - loss: 2.1175\n",
      "Epoch 19/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.0927\n",
      "Epoch 19: loss improved from 2.11755 to 2.09268, saving model to weights-improvement-19-2.0927.hdf5\n",
      "1103/1103 [==============================] - 343s 311ms/step - loss: 2.0927\n",
      "Epoch 20/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.0652\n",
      "Epoch 20: loss improved from 2.09268 to 2.06520, saving model to weights-improvement-20-2.0652.hdf5\n",
      "1103/1103 [==============================] - 347s 314ms/step - loss: 2.0652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2904f0f6da0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f0bb90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-20-2.0652.hdf5\"\n",
    "model.load_weights(filename)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f92ab573",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bac32d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" re was no more to be said.at last the mouse, who seemed to be a person of authority among them,calle \"\n",
      " her head  and the garter wothd the gar and the was soe kant of the care and the was sorednlng to to tea it tat  the was soenk on the tonle th the woudd of the care and the was so tork to toeke th the woudd of the doure tf the woudd of the dareeni,ana the gadt was soe kante was anl toene to the woudd of the dareenii the care an                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4adb889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

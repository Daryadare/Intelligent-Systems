{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d495b6e",
   "metadata": {},
   "source": [
    "## <center>Лабораторная работа № 8 'Генерация текста на основе “Алисы в стране чудес”'<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd92e35",
   "metadata": {},
   "source": [
    "### <center>Выполнила студентка 3 курса группы БФИ2001 Калмыкова Дарья<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d12577",
   "metadata": {},
   "source": [
    "### Цель\n",
    "Использовать рекуррентные нейронные сети в качестве генеративных моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc29bdd9",
   "metadata": {},
   "source": [
    "### Задачи\n",
    "* Ознакомиться с генерацией текста\n",
    "* Ознакомиться с системой Callback в Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdacbfe",
   "metadata": {},
   "source": [
    "### Требования\n",
    "1. Реализовать модель ИНС, которая будет генерировать текст\n",
    "2. Написать собственный CallBack, который будет показывать то как генерируется \n",
    "текст во время обучения (то есть раз в какое-то количество эпох генирировать и \n",
    "выводить текст у необученной модели)\n",
    "3. Отследить процесс обучения при помощи TensorFlowCallBack (TensorBoard), в \n",
    "отчете привести результаты и их анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1925dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy\n",
    "import codecs\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935e949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObj = codecs.open( \"./wonderland.txt\", \"r\", \"utf_8\" )\n",
    "raw_text = fileObj.read()\n",
    "text_clear = re.sub(r\"[\\r\\n]\", '', raw_text)\n",
    "raw_text = text_clear.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f2ff989",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63c44789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c5a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a2cb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  141208\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "print(\"Total Characters: \", n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e917340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocab:  48\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de4d99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  141108\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7e33235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6edac89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669ff1f2",
   "metadata": {},
   "source": [
    "#### Custom callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def period_text_gen():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ac1a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374a77a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3eafd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "318bb5d7",
   "metadata": {},
   "source": [
    "#### Using ModelCheckpoint and TensorBoard callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d253efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', \n",
    "                             verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# keras.callbacks.ModelCheckpoint(\n",
    "#                     filepath = filepath,\n",
    "#                     monitor = 'loss',\n",
    "#                     verbose = 1,\n",
    "#                     save_best_only = True,\n",
    "#                     mode = 'min'\n",
    "#                     ),\n",
    "\n",
    "log_dir = \"lab8_logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "call1 = keras.callbacks.TensorBoard(\n",
    "                    log_dir=log_dir,\n",
    "                    histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf8dec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 3.0054\n",
      "Epoch 1: loss improved from inf to 3.00540, saving model to weights-improvement-01-3.0054.hdf5\n",
      "1103/1103 [==============================] - 412s 371ms/step - loss: 3.0054\n",
      "Epoch 2/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.8351\n",
      "Epoch 2: loss improved from 3.00540 to 2.83508, saving model to weights-improvement-02-2.8351.hdf5\n",
      "1103/1103 [==============================] - 399s 362ms/step - loss: 2.8351\n",
      "Epoch 3/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.7421\n",
      "Epoch 3: loss improved from 2.83508 to 2.74212, saving model to weights-improvement-03-2.7421.hdf5\n",
      "1103/1103 [==============================] - 404s 366ms/step - loss: 2.7421\n",
      "Epoch 4/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.6732\n",
      "Epoch 4: loss improved from 2.74212 to 2.67317, saving model to weights-improvement-04-2.6732.hdf5\n",
      "1103/1103 [==============================] - 401s 363ms/step - loss: 2.6732\n",
      "Epoch 5/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.6137\n",
      "Epoch 5: loss improved from 2.67317 to 2.61372, saving model to weights-improvement-05-2.6137.hdf5\n",
      "1103/1103 [==============================] - 402s 364ms/step - loss: 2.6137\n",
      "Epoch 6/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.5576\n",
      "Epoch 6: loss improved from 2.61372 to 2.55764, saving model to weights-improvement-06-2.5576.hdf5\n",
      "1103/1103 [==============================] - 401s 364ms/step - loss: 2.5576\n",
      "Epoch 7/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.5052\n",
      "Epoch 7: loss improved from 2.55764 to 2.50521, saving model to weights-improvement-07-2.5052.hdf5\n",
      "1103/1103 [==============================] - 401s 364ms/step - loss: 2.5052\n",
      "Epoch 8/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.4575\n",
      "Epoch 8: loss improved from 2.50521 to 2.45749, saving model to weights-improvement-08-2.4575.hdf5\n",
      "1103/1103 [==============================] - 402s 364ms/step - loss: 2.4575\n",
      "Epoch 9/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.4162\n",
      "Epoch 9: loss improved from 2.45749 to 2.41622, saving model to weights-improvement-09-2.4162.hdf5\n",
      "1103/1103 [==============================] - 401s 363ms/step - loss: 2.4162\n",
      "Epoch 10/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.3764\n",
      "Epoch 10: loss improved from 2.41622 to 2.37641, saving model to weights-improvement-10-2.3764.hdf5\n",
      "1103/1103 [==============================] - 432s 392ms/step - loss: 2.3764\n",
      "Epoch 11/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.3393\n",
      "Epoch 11: loss improved from 2.37641 to 2.33928, saving model to weights-improvement-11-2.3393.hdf5\n",
      "1103/1103 [==============================] - 405s 367ms/step - loss: 2.3393\n",
      "Epoch 12/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.3033\n",
      "Epoch 12: loss improved from 2.33928 to 2.30329, saving model to weights-improvement-12-2.3033.hdf5\n",
      "1103/1103 [==============================] - 401s 363ms/step - loss: 2.3033\n",
      "Epoch 13/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.2662\n",
      "Epoch 13: loss improved from 2.30329 to 2.26616, saving model to weights-improvement-13-2.2662.hdf5\n",
      "1103/1103 [==============================] - 406s 368ms/step - loss: 2.2662\n",
      "Epoch 14/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.2350\n",
      "Epoch 14: loss improved from 2.26616 to 2.23505, saving model to weights-improvement-14-2.2350.hdf5\n",
      "1103/1103 [==============================] - 414s 375ms/step - loss: 2.2350\n",
      "Epoch 15/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.1997\n",
      "Epoch 15: loss improved from 2.23505 to 2.19973, saving model to weights-improvement-15-2.1997.hdf5\n",
      "1103/1103 [==============================] - 401s 363ms/step - loss: 2.1997\n",
      "Epoch 16/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.1697\n",
      "Epoch 16: loss improved from 2.19973 to 2.16968, saving model to weights-improvement-16-2.1697.hdf5\n",
      "1103/1103 [==============================] - 399s 362ms/step - loss: 2.1697\n",
      "Epoch 17/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.1381\n",
      "Epoch 17: loss improved from 2.16968 to 2.13815, saving model to weights-improvement-17-2.1381.hdf5\n",
      "1103/1103 [==============================] - 400s 362ms/step - loss: 2.1381\n",
      "Epoch 18/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.1094\n",
      "Epoch 18: loss improved from 2.13815 to 2.10942, saving model to weights-improvement-18-2.1094.hdf5\n",
      "1103/1103 [==============================] - 418s 379ms/step - loss: 2.1094\n",
      "Epoch 19/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.0805\n",
      "Epoch 19: loss improved from 2.10942 to 2.08053, saving model to weights-improvement-19-2.0805.hdf5\n",
      "1103/1103 [==============================] - 415s 376ms/step - loss: 2.0805\n",
      "Epoch 20/20\n",
      "1103/1103 [==============================] - ETA: 0s - loss: 2.0544\n",
      "Epoch 20: loss improved from 2.08053 to 2.05438, saving model to weights-improvement-20-2.0544.hdf5\n",
      "1103/1103 [==============================] - 383s 347ms/step - loss: 2.0544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29544f6f1c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=[checkpoint, call1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c842802f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15416), started 7:36:11 ago. (Use '!kill 15416' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d1c025f1d8f58a6d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d1c025f1d8f58a6d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir lab8_logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d8d57",
   "metadata": {},
   "source": [
    "#### Epoch loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422e9d3",
   "metadata": {},
   "source": [
    "![Epoch loss](./lab8_tb/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db32e4e",
   "metadata": {},
   "source": [
    "#### Time Series on Dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4311861",
   "metadata": {},
   "source": [
    "![Epoch loss](./lab8_tb/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dce65b",
   "metadata": {},
   "source": [
    "#### Histograms of Dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f2ba7e",
   "metadata": {},
   "source": [
    "![](./lab8_tb/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4619a2b",
   "metadata": {},
   "source": [
    "#### Histograms of LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c34a9",
   "metadata": {},
   "source": [
    "![Epoch loss](./lab8_tb/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e97225",
   "metadata": {},
   "source": [
    "### Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f0bb90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-20-2.0652.hdf5\"\n",
    "model.load_weights(filename)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f92ab573",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bac32d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" re was no more to be said.at last the mouse, who seemed to be a person of authority among them,calle \"\n",
      " her head  and the garter wothd the gar and the was soe kant of the care and the was sorednlng to to tea it tat  the was soenk on the tonle th the woudd of the care and the was so tork to toeke th the woudd of the doure tf the woudd of the dareeni,ana the gadt was soe kante was anl toene to the woudd of the dareenii the care an                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4adb889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

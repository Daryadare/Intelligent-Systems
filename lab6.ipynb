{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f1341b",
   "metadata": {
    "id": "a7f1341b"
   },
   "source": [
    "## <center>Лабораторная работа № 6 'Прогноз успеха фильмов по обзорам'<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59804a86",
   "metadata": {
    "id": "59804a86"
   },
   "source": [
    "### <center>Выполнила студентка 3 курса группы БФИ2001 Калмыкова Дарья<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42112078",
   "metadata": {
    "id": "42112078"
   },
   "source": [
    "### Цель\n",
    "Прогноз успеха фильмов по обзорам (Predict Sentiment From Movie Reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b5295a",
   "metadata": {
    "id": "44b5295a"
   },
   "source": [
    "### Задачи\n",
    "* Ознакомиться с задачей классификации\n",
    "* Изучить способы представления текста для передачи в ИНС\n",
    "* Достигнуть точность прогноза не менее 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16feeaf9",
   "metadata": {
    "id": "16feeaf9"
   },
   "source": [
    "### Требования\n",
    "1. Построить и обучить нейронную сеть для обработки текста\n",
    "2. Исследовать результаты при различном размере вектора представления текста\n",
    "3. Написать функцию, которая позволяет ввести пользовательский текст (в отчете \n",
    "привести пример работы сети на пользовательском тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1c8312",
   "metadata": {
    "id": "6a1c8312"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Conv2D\n",
    "from keras.datasets import imdb\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe1ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55e6feb7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55e6feb7",
    "outputId": "60b0ca08-34d9-4f58-9de1-da3a71599fe4"
   },
   "outputs": [],
   "source": [
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86bd1729",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86bd1729",
    "outputId": "b61f340d-254d-40f6-a3af-fb58c77a5486",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: [0 1]\n",
      "Number of unique words: 9998\n"
     ]
    }
   ],
   "source": [
    "print(\"Categories:\", np.unique(targets))\n",
    "print(\"Number of unique words:\", len(np.unique(np.hstack(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b705db",
   "metadata": {
    "id": "a7b705db"
   },
   "outputs": [],
   "source": [
    "length = [len(i) for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d63fa20e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d63fa20e",
    "outputId": "91ba517b-52ba-4853-fb53-03670815feca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Review length: 234.75892\n",
      "Standard Deviation: 173\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Review length:\", np.mean(length))\n",
    "print(\"Standard Deviation:\", round(np.std(length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231478d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "231478d9",
    "outputId": "10cfc91c-b072-4bcf-9f5e-e6ee3d13b599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(\"Label:\", targets[0])\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de6e54c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de6e54c5",
    "outputId": "b3bc1354-15ce-497b-f905-5174a6ba3149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert # is an amazing actor and now the same being director # father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for # and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also # to the two little boy's that played the # of norman and paul they were just brilliant children are often left out of the # list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "index = imdb.get_word_index()\n",
    "reverse_index = dict([(value, key) for (key, value) in index.items()])\n",
    "decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[0]] )\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bdd1fb1",
   "metadata": {
    "id": "1bdd1fb1"
   },
   "outputs": [],
   "source": [
    "def vectorize(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "data = vectorize(data)\n",
    "targets = np.array(targets).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91977fb3",
   "metadata": {
    "id": "91977fb3"
   },
   "outputs": [],
   "source": [
    "test_x = data[:10000]\n",
    "test_y = targets[:10000]\n",
    "train_x = data[10000:]\n",
    "train_y = targets[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22af1299",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22af1299",
    "outputId": "c6fa1b3d-6840-4760-a6da-650fdcdf29d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                500050    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 505,201\n",
      "Trainable params: 505,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "\n",
    "model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "\n",
    "model.add(Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982a2a6d",
   "metadata": {
    "id": "982a2a6d"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", \n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "971541bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "971541bd",
    "outputId": "6724cbbc-ae13-4202-a8fe-266c113986c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "80/80 [==============================] - 3s 25ms/step - loss: 0.4213 - accuracy: 0.8106 - val_loss: 0.2640 - val_accuracy: 0.8933\n",
      "Epoch 2/2\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 0.2211 - accuracy: 0.9160 - val_loss: 0.2585 - val_accuracy: 0.8955\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(train_x, train_y, epochs= 2, batch_size = 500, \n",
    "                    validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ad8bdc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ad8bdc0",
    "outputId": "fa80997e-2978-48d0-9125-23cb2ec968b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8944000005722046\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results.history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84d715",
   "metadata": {
    "id": "bd84d715"
   },
   "source": [
    "### Достигнем максимально возможной точности прогноза на валидационных данных (без применения Transfer Learning, Ensemble Modeling, Word Embeddings, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ed2f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exp = Sequential()\n",
    "\n",
    "model_exp.add(BatchNormalization(synchronized=True))\n",
    "\n",
    "model_exp.add(Dense(60, activation = \"relu\", input_shape=(10000, ),\n",
    "                       kernel_initializer=glorot_uniform()))\n",
    "model_exp.add(Dense(150, activation='relu',\n",
    "                   kernel_initializer=glorot_uniform(), bias_regularizer=l2(0.05)))\n",
    "model_exp.add(Dropout(0.3))\n",
    "\n",
    "model_exp.add(BatchNormalization(synchronized=True))\n",
    "\n",
    "model_exp.add(Dense(90, activation='relu',\n",
    "                   kernel_initializer=glorot_uniform(), bias_regularizer=l2(0.05)))\n",
    "model_exp.add(Dropout(0.2))\n",
    "\n",
    "model_exp.add(BatchNormalization(synchronized=True))\n",
    "\n",
    "model_exp.add(Dense(40, activation='relu',\n",
    "                   kernel_initializer=glorot_uniform(), bias_regularizer=l2(0.05)))\n",
    "model_exp.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c0d497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "115/115 [==============================] - 7s 40ms/step - loss: 0.4059 - accuracy: 0.8076 - val_loss: 0.3257 - val_accuracy: 0.8761\n",
      "Epoch 2/3\n",
      "115/115 [==============================] - 4s 37ms/step - loss: 0.1794 - accuracy: 0.9323 - val_loss: 0.2770 - val_accuracy: 0.8847\n",
      "Epoch 3/3\n",
      "115/115 [==============================] - 4s 37ms/step - loss: 0.1024 - accuracy: 0.9627 - val_loss: 0.3099 - val_accuracy: 0.8847\n",
      "0.8944000005722046\n"
     ]
    }
   ],
   "source": [
    "model_exp.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_exp.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=3, batch_size=350, verbose=1)\n",
    "print(np.mean(results.history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eddab33",
   "metadata": {},
   "source": [
    "### Функция, которая позволяет ввести пользовательский текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f180b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(text):\n",
    "    text_punct = re.sub(r\"[!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]\", ' ', text)\n",
    "    text_numbers = re.sub(r\"[0-9]\", ' ', text_punct)\n",
    "    \n",
    "    text_token = word_tokenize(text_numbers, language='english')\n",
    "#     stop = set(stopwords.words('english'))\n",
    "    text_preproc = [word for word in text_token]\n",
    "    \n",
    "    return text_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12937a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(words_prep):\n",
    "    res = []\n",
    "    for i in range(len(words_prep)):\n",
    "        word_index = imdb.get_word_index()\n",
    "        word = words_prep[i]\n",
    "        if word_index[word] < 10000:\n",
    "            res.append(word_index[word])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce52dd8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_res(pred):\n",
    "    if pred>0.5:\n",
    "        print(f'Great film I guess {pred}') \n",
    "    else: print(f'What was all the puff about that... {pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ecd7b",
   "metadata": {},
   "source": [
    "#### Positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "775c43cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your movie review: When you very nearly spray a mouthful of drink over the person in front of you, its generally a good indicator the movie is pretty funny. The sandwich joke had me in stitches! This movie doesn't rely on just a few jokes to carry it, they maintain a subtle layer of humour throughout and then have you in stitches with some brilliant jokes. The cast in this movie are well picked and really gets the whole dilemma of everyday life as a vampire! Hopefully this gets picked up and the masses get a chance to enjoy this wee gem. Loved this movie and would definitely recommend it. Gave this a 10. A must see!!\n"
     ]
    }
   ],
   "source": [
    "text_string = str(input('Input your movie review: '))\n",
    "words = preproc(text_string.lower())\n",
    "words_idx = get_index(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f3ea3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_words = vectorize([words_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d36d3a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 123ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(fin_words)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4f855aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great film I guess 0.863459050655365\n"
     ]
    }
   ],
   "source": [
    "get_res(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2030e7",
   "metadata": {},
   "source": [
    "#### Negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ff454ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your movie review: It's a refreshing idea but this is amateur hour and looks like a film made by a bunch of film students. I didn't laugh once, not even a giggle. 95% of it is filmed inside a dark house which just adds to the dreariness of it all. It's slow and I can't see it going into cinema release in the states. I have liked a few oddball comedies from New Zeland but I will remember this one for all the wrong reasons. Just awful!\n"
     ]
    }
   ],
   "source": [
    "text_string = str(input('Input your movie review: '))\n",
    "words = preproc(text_string.lower())\n",
    "words_idx = get_index(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1959c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_words = vectorize([words_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a236a8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(fin_words)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ca6008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was all the puff about that... 0.3691744804382324\n"
     ]
    }
   ],
   "source": [
    "get_res(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110259c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

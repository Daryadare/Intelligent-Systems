{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4826cd",
   "metadata": {},
   "source": [
    "## <center>Лабораторная работа № 7 'Классификация обзоров фильмов'<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46148fd",
   "metadata": {},
   "source": [
    "### <center>Выполнила студентка 3 курса группы БФИ2001 Калмыкова Дарья<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38241895",
   "metadata": {},
   "source": [
    "### Цель\n",
    "Обучение на датасете IMDB с помощью рекуррентной нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d78bbd",
   "metadata": {},
   "source": [
    "### Задачи\n",
    "* Ознакомиться с задачей рекуррентными нейронными сетями\n",
    "* Изучить способы классификации текста\n",
    "* Ознакомиться с ансамблированием сетей\n",
    "* Построить ансамбль сетей, который позволит получать точность не менее 97%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6077a56",
   "metadata": {},
   "source": [
    "### Требования\n",
    "1. Найти набор оптимальных ИНС для классификации текста\n",
    "2. Провести ансамблирование моделей\n",
    "3. Написать функцию/функции, которые позволят загружать текст и получать \n",
    "результат ансамбля сетей\n",
    "4. Провести тестирование сетей на своих текстах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30daea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dense, LSTM, Embedding, Conv1D, MaxPooling1D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.saving import load_model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9465150",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "data = np.concatenate((X_train, X_test), axis=0)\n",
    "targets = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632b7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 500\n",
    "embedding_vecor_length = 32\n",
    "X_train = pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0d485",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dba15e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               53200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_base = Sequential()\n",
    "\n",
    "model_base.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model_base.add(LSTM(100))\n",
    "model_base.add(Dense(1, activation='sigmoid'))\n",
    "model_base.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019e7acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "391/391 [==============================] - 340s 865ms/step - loss: 0.4668 - accuracy: 0.7717 - val_loss: 0.3522 - val_accuracy: 0.8496\n",
      "Epoch 2/2\n",
      "391/391 [==============================] - 352s 902ms/step - loss: 0.3047 - accuracy: 0.8757 - val_loss: 0.3133 - val_accuracy: 0.8690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a60d549480>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_base.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62ea0e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.90%\n"
     ]
    }
   ],
   "source": [
    "scores = model_base.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b25728",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c02113",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model1.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model1.add(LSTM(120))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "722fcab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 500, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 250, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 120)               73440     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 121       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 236,665\n",
      "Trainable params: 236,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d61a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "391/391 [==============================] - 156s 394ms/step - loss: 0.4584 - accuracy: 0.7676 - val_loss: 0.3009 - val_accuracy: 0.8788\n",
      "Epoch 2/2\n",
      "391/391 [==============================] - 148s 378ms/step - loss: 0.2470 - accuracy: 0.9038 - val_loss: 0.3055 - val_accuracy: 0.8804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a6025f4610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0be22f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 41s 52ms/step - loss: 0.3055 - accuracy: 0.8804\n",
      "Accuracy: 88.04%\n"
     ]
    }
   ],
   "source": [
    "scores = model1.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc7669",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4beca2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model2.add(LSTM(30))\n",
    "\n",
    "model2.add(Dense(200, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Dense(100, activation='relu'))\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "model2.add(Dense(50, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d708ec2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 30)                7560      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               6200      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 198,961\n",
      "Trainable params: 198,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6db50ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "391/391 [==============================] - 87s 217ms/step - loss: 0.4362 - accuracy: 0.7846 - val_loss: 0.3747 - val_accuracy: 0.8492\n",
      "Epoch 2/4\n",
      "391/391 [==============================] - 84s 215ms/step - loss: 0.2613 - accuracy: 0.8986 - val_loss: 0.2949 - val_accuracy: 0.8762\n",
      "Epoch 3/4\n",
      "391/391 [==============================] - 83s 211ms/step - loss: 0.2231 - accuracy: 0.9147 - val_loss: 0.2975 - val_accuracy: 0.8794\n",
      "Epoch 4/4\n",
      "391/391 [==============================] - 83s 213ms/step - loss: 0.1878 - accuracy: 0.9303 - val_loss: 0.3116 - val_accuracy: 0.8744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a6032e3f70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ddc4d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 33s 42ms/step - loss: 0.3116 - accuracy: 0.8744\n",
      "Accuracy: 87.44%\n"
     ]
    }
   ],
   "source": [
    "scores = model2.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91216490",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46a57319",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "\n",
    "model3.add(Dense(250, activation='selu', kernel_initializer=glorot_uniform(), bias_regularizer=l2(0.05)))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(LSTM(50))\n",
    "\n",
    "model3.add(Dense(110, activation='selu', kernel_initializer=glorot_uniform(), bias_regularizer=l2(0.05)))\n",
    "model3.add(Dropout(0.3))\n",
    "\n",
    "model3.add(Dense(50, activation='selu', kernel_initializer=glorot_uniform(), bias_regularizer=l2(0.05)))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33fe2b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 500, 250)          8250      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 500, 250)          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 50)                60200     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 110)               5610      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 110)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 50)                5550      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 239,661\n",
      "Trainable params: 239,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be17a492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "391/391 [==============================] - 221s 559ms/step - loss: 0.4483 - accuracy: 0.7787 - val_loss: 0.3194 - val_accuracy: 0.8698\n",
      "Epoch 2/2\n",
      "391/391 [==============================] - 220s 564ms/step - loss: 0.2818 - accuracy: 0.8885 - val_loss: 0.3130 - val_accuracy: 0.8717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a605129930>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b82d424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 65s 83ms/step - loss: 0.3130 - accuracy: 0.8717\n",
      "Accuracy: 87.17%\n"
     ]
    }
   ],
   "source": [
    "scores = model3.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fecc5eb",
   "metadata": {},
   "source": [
    "### Saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50e82c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base.save('model_base.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16695758",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('model1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8815ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('model2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b7c1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('model3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1aff9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_base = load_model('model_base.keras')\n",
    "loaded_model1 = load_model('model1.keras')\n",
    "loaded_model2 = load_model('model2.keras')\n",
    "loaded_model3 = load_model('model3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0921d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = [loaded_model_base, loaded_model1, loaded_model2, loaded_model3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8664c79b",
   "metadata": {},
   "source": [
    "### Stacking as Ensemble Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46b9f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stacked model input dataset as outputs from the ensemble\n",
    "\n",
    "def stacked_dataset(all_models, X_input):\n",
    "    X_stack = None\n",
    "    for mdl in all_models:\n",
    "        pred = mdl.predict(X_input, verbose=1)\n",
    "        \n",
    "        if X_stack is None:\n",
    "            X_stack = pred\n",
    "        else:\n",
    "            X_stack = np.dstack((X_stack, pred))\n",
    "    \n",
    "    # flatten predictions to [rows, members x probabilities]\n",
    "    X_stack = X_stack.reshape((X_stack.shape[0], X_stack.shape[1]*X_stack.shape[2]))\n",
    "    return X_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77a95a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_stacked_model(all_models, X_train, y_train):\n",
    "    X_stacked = stacked_dataset(all_models, X_train)\n",
    "    \n",
    "    model_gbc = GradientBoostingClassifier()\n",
    "    model_gbc.fit(X_stacked, y_train)\n",
    "    \n",
    "    return model_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed5dd92a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 69s 88ms/step\n",
      "782/782 [==============================] - 41s 52ms/step\n",
      "782/782 [==============================] - 35s 44ms/step\n",
      "782/782 [==============================] - 61s 78ms/step\n"
     ]
    }
   ],
   "source": [
    "stacked_model = fit_stacked_model(all_models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c140e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 73s 93ms/step\n",
      "782/782 [==============================] - 41s 52ms/step\n",
      "782/782 [==============================] - 39s 50ms/step\n",
      "782/782 [==============================] - 60s 76ms/step\n",
      "87.868\n"
     ]
    }
   ],
   "source": [
    "def stacked_prediction(all_models, stacked_model, X_test):\n",
    "    X_stacked = stacked_dataset(all_models, X_test)\n",
    "    pred = stacked_model.predict(X_stacked)\n",
    "    return pred\n",
    "\n",
    "y_pred = stacked_prediction(all_models, stacked_model, X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c8e33",
   "metadata": {},
   "source": [
    "### Fucntion to test user's review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b91a7739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(text):\n",
    "    text_punct = re.sub(r\"[!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]\", ' ', text)\n",
    "    text_numbers = re.sub(r\"[0-9]\", ' ', text_punct)\n",
    "    \n",
    "    text_token = word_tokenize(text_numbers, language='english')\n",
    "    text_preproc = [word for word in text_token]\n",
    "    \n",
    "    return text_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0525452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(words_prep):\n",
    "    res = []\n",
    "    for i in range(len(words_prep)):\n",
    "        word_index = imdb.get_word_index()\n",
    "        word = words_prep[i]\n",
    "        if word_index[word] < 500:\n",
    "            res.append(word_index[word])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05032a6c",
   "metadata": {},
   "source": [
    "### Positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35656d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your movie review: When you very nearly spray a mouthful of drink over the person in front of you, its generally a good indicator the movie is pretty funny. The sandwich joke had me in stitches! This movie doesn't rely on just a few jokes to carry it, they maintain a subtle layer of humour throughout and then have you in stitches with some brilliant jokes. The cast in this movie are well picked and really gets the whole dilemma of everyday life as a vampire! Hopefully this gets picked up and the masses get a chance to enjoy this wee gem. Loved this movie and would definitely recommend it. Gave this a 10. A must see!!\n"
     ]
    }
   ],
   "source": [
    "text_string = str(input('Input your movie review: '))\n",
    "words = preproc(text_string.lower())\n",
    "words_idx = get_index(words)\n",
    "words_pad = pad_sequences([words_idx], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "abb7f559",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    }
   ],
   "source": [
    "words_stacked = stacked_dataset(all_models, words_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dd396eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02288681 0.97711319]]\n"
     ]
    }
   ],
   "source": [
    "pred = stacked_model.predict_proba(words_stacked)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18a5f7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_model.score(words_stacked, [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb14ec",
   "metadata": {},
   "source": [
    "### Negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "adaf180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your movie review: Almost 3 hours wasted of my time. Garbage movie - plot wise. The plot has more holes than a Swiss cheese. Acting is okay, story though, ugh, what a poor attempt.\n"
     ]
    }
   ],
   "source": [
    "text_string = str(input('Input your movie review: '))\n",
    "words = preproc(text_string.lower())\n",
    "words_idx = get_index(words)\n",
    "words_pad = pad_sequences([words_idx], maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d8a6337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "words_stacked = stacked_dataset(all_models, words_pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ff3a14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64621774 0.35378226]]\n"
     ]
    }
   ],
   "source": [
    "pred = stacked_model.predict_proba(words_stacked)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a8d9e9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_model.score(words_stacked, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad8cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
